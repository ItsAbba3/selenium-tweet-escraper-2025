{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3d8cc-624e-4772-82c2-ba053f55e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Path to your ChromeDriver executable\n",
    "chromedriver_path = \"Your/chrome/driver/path\n",
    "\n",
    "# User credentials\n",
    "username = 'your/username'\n",
    "password = 'your/paasword'\n",
    "# Twitter user ID for profile extraction will be provided as input later\n",
    "\n",
    "# Set up Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')     # Run browser in headless mode (without UI)\n",
    "options.add_argument('--disable-gpu')  # Disable GPU acceleration\n",
    "\n",
    "# Initialize WebDriver service\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "\n",
    "# Launch browser\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "def login_twitter(username, password):\n",
    "    \"\"\"\n",
    "    Log in to Twitter using provided username and password.\n",
    "    \"\"\"\n",
    "    driver.get('https://twitter.com/login')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Enter username/email\n",
    "    username_input = driver.find_element(By.NAME, 'text')\n",
    "    username_input.send_keys(username)\n",
    "    username_input.send_keys(Keys.RETURN)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Enter password\n",
    "    password_input = driver.find_element(By.NAME, 'password')\n",
    "    password_input.send_keys(password)\n",
    "    password_input.send_keys(Keys.RETURN)\n",
    "    time.sleep(5)\n",
    "\n",
    "# Perform login\n",
    "login_twitter(username, password)\n",
    "\n",
    "def extract_twitter_info(user_id, max_tweets=100):\n",
    "    \"\"\"\n",
    "    Extract tweets, user name, and bio from a Twitter profile.\n",
    "    \n",
    "    :param user_id: Twitter user ID (username)\n",
    "    :param max_tweets: Maximum number of tweets to collect\n",
    "    :return: Dictionary containing user name, bio, and a list of tweets\n",
    "    \"\"\"\n",
    "    # Construct the profile URL\n",
    "    profile_url = f'https://twitter.com/{user_id}'\n",
    "    \n",
    "    # Navigate to the user's profile page\n",
    "    driver.get(profile_url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    collected_tweets = []  # List to store tweets\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while len(collected_tweets) < max_tweets:\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "        # Extract tweet elements using data-testid attribute\n",
    "        tweet_elements = soup.find_all('div', {'data-testid': 'tweetText'})\n",
    "        for tweet in tweet_elements:\n",
    "            tweet_text = tweet.get_text(strip=True)\n",
    "            if tweet_text not in collected_tweets:\n",
    "                collected_tweets.append(tweet_text)\n",
    "                if len(collected_tweets) >= max_tweets:\n",
    "                    break\n",
    "        \n",
    "        # Scroll down to load more tweets\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Check if scrolling has reached the bottom\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            print(\"No more tweets to load.\")\n",
    "            break\n",
    "        last_height = new_height\n",
    "    \n",
    "    # Extract user name and bio\n",
    "    user_name_element = soup.find('div', {'data-testid': 'UserName'})\n",
    "    if user_name_element:\n",
    "        user_name = user_name_element.find('div').find('span').text\n",
    "    else:\n",
    "        user_name = \"N/A\"\n",
    "    \n",
    "    bio_element = soup.find('div', {'data-testid': 'UserDescription'})\n",
    "    bio = bio_element.text if bio_element else \"N/A\"\n",
    "\n",
    "    # Format the collected data\n",
    "    profile_data = {\n",
    "        \"user_name\": user_name,\n",
    "        \"bio\": bio,\n",
    "        \"tweets\": collected_tweets[:max_tweets]\n",
    "    }\n",
    "    \n",
    "    return profile_data\n",
    "\n",
    "# Get Twitter user ID input from the user\n",
    "user_id = input(\"Enter the Twitter user ID: \")\n",
    "\n",
    "# Extract profile data\n",
    "profile_data = extract_twitter_info(user_id, max_tweets=100)\n",
    "\n",
    "# Save extracted data to a JSON file\n",
    "with open(f'{user_id}.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(profile_data, f, ensure_ascii=False, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
